{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with loading in the libraries, reading the data and exploring the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading file into dataframe\n",
    "df = pd.read_csv('Prepared_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing head of the dataframe \n",
    "print(df.head())\n",
    "#printing the shape of the df\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewing the columns inside the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "def kendall_pval(x,y):\n",
    "    return kendalltau(x,y)[1]\n",
    "\n",
    "def pearsonr_pval(x,y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "def spearmanr_pval(x,y):\n",
    "    return spearmanr(x,y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - \n",
    "### Finding Correlations between Target Variable and Predictor Variables\n",
    "\n",
    "We will use the value of these correlations to find target variables. Ideally higher correlations mean high predictive power. Using the columns which have the highest correlations, we will apply linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding correlation between amount of delay and rest of the dataframe\n",
    "\n",
    "Corr_Matrix_1 = pd.DataFrame(df.drop(['Delayed','PROJECT_ID','Times_Delayed'], axis=1).corr(method ='pearson')['Amount_of_Delay_(Quarters)'])\n",
    "Corr_Matrix_1 = Corr_Matrix_1.reindex(Corr_Matrix_1['Amount_of_Delay_(Quarters)'].abs().sort_values(ascending=False).index)\n",
    "print(Corr_Matrix_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = np.array(df.drop(['Initial_completion_date','final_completion_date','Delayed','PROJECT_ID','Times_Delayed','REGION','MUNICIPALITY'], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#plotting the correlation along with the regression line\n",
    "#looping through each of the numeric columns\n",
    "for col in cols:\n",
    "    plt.scatter(df[col],np.array(df['Amount_of_Delay_(Quarters)']))\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Amount_of_Delay_(Quarters)')\n",
    "    results = sm.OLS(np.array(df['Amount_of_Delay_(Quarters)']),sm.add_constant(np.array(df[col]))).fit()\n",
    "    X_plot = np.linspace(0,1,100)\n",
    "    plt.plot(X_plot, X_plot*results.params[0] + results.params[1])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables chosen for 1st iteration\n",
    "We have chosen to run the following variables for the first iteration of our regression model. These have the highest correlation - 'CST_Mixed_Use','Type_Owner_priv','PUBLIC_FUNDING_IND','CST_Education','CT_Institutional'\n",
    "\n",
    "Note - We excluded Age because of colinearity issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['CST_Mixed_Use','Type_Owner_priv','PUBLIC_FUNDING_IND','CST_Education','CT_Institutional']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without a constant\n",
    "\n",
    "\n",
    "\n",
    "#Applying Stats model \n",
    "\n",
    "y = df[\"Amount_of_Delay_(Quarters)\"]\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that two of the variables have high P-values. Thus we need to remove them because keeping them in the model means are model is not statistically significant, which implies that we cannot reject the null hypothesis that the variables were indeed by chance correlated with the main target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['CST_Mixed_Use','Type_Owner_priv','PUBLIC_FUNDING_IND']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-applying the model\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - \n",
    "### Finding Correlations between Target Variable and Predictor Variables\n",
    "\n",
    "We will use the value of these correlations to find target variables. Ideally higher correlations mean high predictive power. Using the columns which have the highest correlations, we will apply linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_Matrix_2 = pd.DataFrame(df.drop(['Budget_Overrun','PROJECT_ID','Final_Estimated_Budget'], axis=1).corr(method ='pearson')['percentage_of_overrun'])\n",
    "Corr_Matrix_2 = Corr_Matrix_2.reindex(Corr_Matrix_2['percentage_of_overrun'].abs().sort_values(ascending=False).index)\n",
    "print(Corr_Matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#plotting the correlation along with the regression line\n",
    "#looping through each of the numeric columns\n",
    "for col in cols:\n",
    "    plt.scatter(df[col],np.array(df['percentage_of_overrun']))\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Amount_of_Delay_(Quarters)')\n",
    "    results = sm.OLS(np.array(df['percentage_of_overrun']),sm.add_constant(np.array(df[col]))).fit()\n",
    "    X_plot = np.linspace(0,1,100)\n",
    "    plt.plot(X_plot, X_plot*results.params[0] + results.params[1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation values in all the cases are very low. To fit the model we will use the top 5 correlated columns as predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df[['Region_others','CST_Roads_Highways','Amount_of_Delay_(Quarters)','Type_Owner_prov','Times_Delayed']]\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = df[\"percentage_of_overrun\"]\n",
    "\n",
    "# Note the difference in argument order\n",
    "model2 = sm.OLS(y2, X2).fit()\n",
    "predictions = model2.predict(X2) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the variables which have high p values or low statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df[['Region_others','CST_Roads_Highways']]\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = sm.OLS(y2, X2).fit()\n",
    "predictions = model2.predict(X2) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needless to say the values of this model in terms of accuracy are very poor. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
